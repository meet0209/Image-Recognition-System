{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9f2f15",
   "metadata": {},
   "source": [
    "# Building and Training a Convolutional Neural Network on the Fashion MNIST Dataset using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d22dc4",
   "metadata": {},
   "source": [
    "## This Python script uses the Keras library to build, train, and evaluate a Convolutional Neural Network (CNN) for the Fashion MNIST dataset.\n",
    "\n",
    "Here's a brief summary of each section:\n",
    "\n",
    "1. Import necessary libraries and modules: The script imports necessary modules from Keras, including the Fashion MNIST dataset, the Sequential model, Dense and Flatten layers, Conv2D for convolutional layers, and a utility function for categorical conversion.\n",
    "\n",
    "2. Load and preprocess data: The Fashion MNIST dataset is loaded and split into training and testing sets. The pixel values of the images are normalized to be between 0 and 1. The images are reshaped to have one channel, which is required for the CNN.\n",
    "\n",
    "3. Create the model: A Sequential model is created and configured with one convolutional layer (Conv2D), a flattening layer (Flatten), and a dense layer. The activation function for the Conv2D layer is 'relu', and for the Dense layer, it's 'softmax'.\n",
    "\n",
    "4. Compile the model: The model is compiled with the 'adam' optimizer, 'sparse_categorical_crossentropy' as the loss function, and 'accuracy' as the metric.\n",
    "\n",
    "5. Train the model: The model is trained on the training data for 10 epochs with a batch size of 64.\n",
    "\n",
    "6. Evaluate the model: The trained model is evaluated on the test data, and the test accuracy is printed out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07933cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 17ms/step - loss: 0.4316 - accuracy: 0.8484\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2995 - accuracy: 0.8942\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2634 - accuracy: 0.9059\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2396 - accuracy: 0.9150\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2195 - accuracy: 0.9205\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2033 - accuracy: 0.9276\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1888 - accuracy: 0.9328\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1770 - accuracy: 0.9365\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1647 - accuracy: 0.9411\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1532 - accuracy: 0.9457\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2886 - accuracy: 0.9053\n",
      "Test accuracy: 0.9053000211715698\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load data\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Reshape the images to have one channel\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e363162",
   "metadata": {},
   "source": [
    "## This output represents the training and testing process of the Convolutional Neural Network (CNN) on the Fashion MNIST dataset.\n",
    "\n",
    "1. Training: The model is trained for 10 epochs. For each epoch, the model goes through the entire training dataset. The 'loss' and 'accuracy' are calculated after each epoch. The 'loss' is a measure of the model's error, and 'accuracy' is the proportion of correct predictions. The loss decreases and accuracy increases with each epoch, indicating that the model is learning and improving its performance.\n",
    "\n",
    "- Epoch 1: The model starts with a loss of 0.4316 and accuracy of 0.8484.\n",
    "- Epoch 10: By the end of the 10th epoch, the model has a loss of 0.1532 and accuracy of 0.9457. This shows that the model has significantly improved its performance over the 10 epochs.\n",
    "\n",
    "2. Testing: After training, the model is evaluated on the test dataset. The test loss and accuracy are calculated. The test loss is 0.2886 and the test accuracy is 0.9053. This means that the model correctly predicts the class of the images in the test set about 90.53% of the time.\n",
    "\n",
    "The difference between training accuracy (94.57%) and testing accuracy (90.53%) suggests that the model might be slightly overfitting on the training data. Overfitting is when a model performs well on the training data but less well on unseen data (like the test data). This could be addressed by techniques like regularization, dropout, or gathering more data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
